{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data_to_score/mnist_png/\\n -- \\n \\n../data_to_score/source_celebA/\\nCalculating Inception Score with 10000 images in 10 splits\\nInception Score calculation time: 119.972040 s\\n(3.8423252, 0.1165736)\\n -- \\n \\n../data_to_score/artDCGAN_portrait128/\\nCalculating Inception Score with 1024 images in 10 splits\\nInception Score calculation time: 11.168085 s\\n(3.1664667, 0.28861612)\\n -- \\n \\n../data_to_score/noise64/\\nCalculating Inception Score with 9999 images in 10 splits\\nInception Score calculation time: 107.406403 s\\n(1.0988984, 0.0035116186)\\n -- \\n \\n../data_to_score/artDCGAN_nudeportrait128_scaled64/\\nCalculating Inception Score with 1024 images in 10 splits\\nInception Score calculation time: 10.964800 s\\n(4.149658, 0.30474305)\\n -- \\n \\n../data_to_score/source_landscape128/\\nCalculating Inception Score with 3162 images in 10 splits\\nInception Score calculation time: 34.216549 s\\n(3.8488636, 0.15314613)\\n -- \\n \\n../data_to_score/artDCGAN_portrait128_scaled64/\\nCalculating Inception Score with 1024 images in 10 splits\\nInception Score calculation time: 11.014997 s\\n(3.5496755, 0.21673256)\\n -- \\n \\n../data_to_score/source_landscape128_scaled64/\\nCalculating Inception Score with 3162 images in 10 splits\\nInception Score calculation time: 33.701664 s\\n(3.8234296, 0.23985933)\\n -- \\n \\n../data_to_score/landscapeGANGogh/\\nCalculating Inception Score with 768 images in 10 splits\\nInception Score calculation time: 8.263573 s\\n(2.4535227, 0.15228619)\\n -- \\n \\n../data_to_score/artDCGAN_nudeportrait128/\\nCalculating Inception Score with 1024 images in 10 splits\\nInception Score calculation time: 11.201888 s\\n(3.8906925, 0.37686175)\\n -- \\n \\n../data_to_score/noise128/\\nCalculating Inception Score with 10000 images in 10 splits\\nInception Score calculation time: 108.613862 s\\n(1.0879244, 0.0012194366)\\n -- \\n \\n../data_to_score/source_landscape128_scaled32/\\nCalculating Inception Score with 3162 images in 10 splits\\nInception Score calculation time: 33.715450 s\\n(3.477707, 0.13745134)\\n -- \\n \\n../data_to_score/source_landscape64/\\nCalculating Inception Score with 9999 images in 10 splits\\nInception Score calculation time: 107.434785 s\\n(4.854462, 0.09549643)\\n -- \\n \\n../data_to_score/source_portrait128/\\nCalculating Inception Score with 3064 images in 10 splits\\nInception Score calculation time: 33.020121 s\\n(4.2285333, 0.19791368)\\n -- \\n \\n../data_to_score/artDCGAN_landscape128_scaled64/\\nCalculating Inception Score with 1024 images in 10 splits\\nInception Score calculation time: 10.981993 s\\n(3.9322937, 0.17959179)\\n -- \\n \\n../data_to_score/landscapeGANGogh_scaled128/\\nCalculating Inception Score with 768 images in 10 splits\\nInception Score calculation time: 8.362528 s\\n(2.388645, 0.1225642)\\n -- \\n \\n../data_to_score/WGAN-GP_highdim/\\nCalculating Inception Score with 64 images in 10 splits\\nInception Score calculation time: 0.818775 s\\n(1.0856012, 0.0104307225)\\n -- \\n \\n../data_to_score/landscapeGANGogh_scaled32/\\nCalculating Inception Score with 768 images in 10 splits\\nInception Score calculation time: 8.218182 s\\n(2.9641025, 0.17274365)\\n -- \\n \\n../data_to_score/source_celebA_scaled64/\\nCalculating Inception Score with 10000 images in 10 splits\\nInception Score calculation time: 107.552935 s\\n(2.9762135, 0.05283318)\\n -- \\n \\n../data_to_score/DCGAN_celebA/\\nCalculating Inception Score with 6656 images in 10 splits\\nInception Score calculation time: 71.545108 s\\n(2.2023766, 0.030099742)\\n -- \\n \\n../data_to_score/artDCGAN_landscape128_scaled32/\\nCalculating Inception Score with 1024 images in 10 splits\\nInception Score calculation time: 10.931262 s\\n(3.4998581, 0.21547426)\\n -- \\n \\n../data_to_score/WGAN-GP_brownart/\\nCalculating Inception Score with 64 images in 10 splits\\nInception Score calculation time: 0.818230 s\\n(1.2153931, 0.06912627)\\n -- \\n \\n../data_to_score/source_nudeportrait128/\\nCalculating Inception Score with 3033 images in 10 splits\\nInception Score calculation time: 32.902818 s\\n(5.1888285, 0.29272532)\\n -- \\n \\n../data_to_score/artDCGAN_landscape128/\\nCalculating Inception Score with 1024 images in 10 splits\\nInception Score calculation time: 11.148733 s\\n(3.296584, 0.24069574)\\n -- \\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (\"Inception.txt\", \"r\") as myfile:\n",
    "    data=myfile.read()\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_png\n",
      "source_celebA\n",
      "artDCGAN_portrait128\n",
      "noise64\n",
      "artDCGAN_nudeportrait128_scaled64\n",
      "source_landscape128\n",
      "artDCGAN_portrait128_scaled64\n",
      "source_landscape128_scaled64\n",
      "landscapeGANGogh\n",
      "artDCGAN_nudeportrait128\n",
      "noise128\n",
      "source_landscape128_scaled32\n",
      "source_landscape64\n",
      "source_portrait128\n",
      "artDCGAN_landscape128_scaled64\n",
      "landscapeGANGogh_scaled128\n",
      "WGAN-GP_highdim\n",
      "landscapeGANGogh_scaled32\n",
      "source_celebA_scaled64\n",
      "DCGAN_celebA\n",
      "artDCGAN_landscape128_scaled32\n",
      "WGAN-GP_brownart\n",
      "source_nudeportrait128\n",
      "artDCGAN_landscape128\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "result_name = re.findall('../data_to_score/(.*)/\\n', data)\n",
    "for res in result_name:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8423252\n",
      "3.1664667\n",
      "1.0988984\n",
      "4.149658\n",
      "3.8488636\n",
      "3.5496755\n",
      "3.8234296\n",
      "2.4535227\n",
      "3.8906925\n",
      "1.0879244\n",
      "3.477707\n",
      "4.854462\n",
      "4.2285333\n",
      "3.9322937\n",
      "2.388645\n",
      "1.0856012\n",
      "2.9641025\n",
      "2.9762135\n",
      "2.2023766\n",
      "3.4998581\n",
      "1.2153931\n",
      "5.1888285\n",
      "3.296584\n"
     ]
    }
   ],
   "source": [
    "result_Inception = re.findall('\\((.*),', data)\n",
    "for res in result_Inception:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.1165736\n",
      " 0.28861612\n",
      " 0.0035116186\n",
      " 0.30474305\n",
      " 0.15314613\n",
      " 0.21673256\n",
      " 0.23985933\n",
      " 0.15228619\n",
      " 0.37686175\n",
      " 0.0012194366\n",
      " 0.13745134\n",
      " 0.09549643\n",
      " 0.19791368\n",
      " 0.17959179\n",
      " 0.1225642\n",
      " 0.0104307225\n",
      " 0.17274365\n",
      " 0.05283318\n",
      " 0.030099742\n",
      " 0.21547426\n",
      " 0.06912627\n",
      " 0.29272532\n",
      " 0.24069574\n"
     ]
    }
   ],
   "source": [
    "result_std = re.findall(',(.*)\\)', data)\n",
    "for res in result_std:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(result_name[1:]) + \",\" + pd.Series(result_Inception) + \",\" + pd.Series(result_std)  +\",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_celebA,3.8423252, 0.1165736,\n",
      "artDCGAN_portrait128,3.1664667, 0.28861612,\n",
      "noise64,1.0988984, 0.0035116186,\n",
      "artDCGAN_nudeportrait128_scaled64,4.149658, 0.30474305,\n",
      "source_landscape128,3.8488636, 0.15314613,\n",
      "artDCGAN_portrait128_scaled64,3.5496755, 0.21673256,\n",
      "source_landscape128_scaled64,3.8234296, 0.23985933,\n",
      "landscapeGANGogh,2.4535227, 0.15228619,\n",
      "artDCGAN_nudeportrait128,3.8906925, 0.37686175,\n",
      "noise128,1.0879244, 0.0012194366,\n",
      "source_landscape128_scaled32,3.477707, 0.13745134,\n",
      "source_landscape64,4.854462, 0.09549643,\n",
      "source_portrait128,4.2285333, 0.19791368,\n",
      "artDCGAN_landscape128_scaled64,3.9322937, 0.17959179,\n",
      "landscapeGANGogh_scaled128,2.388645, 0.1225642,\n",
      "WGAN-GP_highdim,1.0856012, 0.0104307225,\n",
      "landscapeGANGogh_scaled32,2.9641025, 0.17274365,\n",
      "source_celebA_scaled64,2.9762135, 0.05283318,\n",
      "DCGAN_celebA,2.2023766, 0.030099742,\n",
      "artDCGAN_landscape128_scaled32,3.4998581, 0.21547426,\n",
      "WGAN-GP_brownart,1.2153931, 0.06912627,\n",
      "source_nudeportrait128,5.1888285, 0.29272532,\n",
      "artDCGAN_landscape128,3.296584, 0.24069574,\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
