{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:701: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      ">> Downloading http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz 63.3%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz 81.6%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz 100.0%WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "from FrechetInceptionDistance.fid import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def load_images_from_folder(folder, nmax=10000):\n",
    "    images = []\n",
    "    images_transposed = []\n",
    "    for filename in os.listdir(folder)[:nmax]:\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            images_transposed.append(img.transpose((-1, 0, 1)))\n",
    "    return np.asarray(images), np.asarray(images_transposed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "folder_pairs = [\n",
    "    (\"../data_to_score/source_landscape128\", \"../data_to_score/artDCGAN_landscape128\"),\n",
    "    (\"../data_to_score/source_portrait128\", \"../data_to_score/artDCGAN_portrait128\"),\n",
    "    (\"../data_to_score/source_nudeportrait128\", \"../data_to_score/artDCGAN_nudeportrait128\"),\n",
    "    \n",
    "    (\"../data_to_score/source_landscape128\", \"../data_to_score/noise128\"),\n",
    "    (\"../data_to_score/source_portrait128\", \"../data_to_score/noise128\"),\n",
    "    (\"../data_to_score/source_nudeportrait128\", \"../data_to_score/noise128\"),\n",
    "    \n",
    "    (\"../data_to_score/source_landscape64\", \"../data_to_score/landscapeGANGogh\"),\n",
    "    (\"../data_to_score/source_landscape64\", \"../data_to_score/noise64\"),\n",
    "    \n",
    "    ## Scaled stuff\n",
    "    (\"../data_to_score/source_landscape128\", \"../data_to_score/landscapeGANGogh_scaled128\"),    \n",
    "    (\"../data_to_score/source_landscape64\", \"../data_to_score/artDCGAN_landscape128_scaled64\"), \n",
    "    (\"../data_to_score/source_landscape128_scaled32\", \"../data_to_score/artDCGAN_landscape128_scaled32\"), \n",
    "    ('../data_to_score/source_landscape128_scaled64', '../data_to_score/artDCGAN_landscape128_scaled64')\n",
    "    ('../data_to_score/source_landscape128_scaled64', '../data_to_score/landscapeGANGogh')\n",
    "    ('../data_to_score/source_landscape128_scaled32', '../data_to_score/landscapeGANGogh_scaled32')\n",
    "    \n",
    "    ## CelebA\n",
    "    \n",
    "]\n",
    "\n",
    "('../data_to_score/source_landscape128', '../data_to_score/artDCGAN_landscape128')\n",
    "Calculating FID with 1024 images from each distribution\n",
    "FID calculation time: 117.896456 s\n",
    "FID: 134.74667\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_portrait128', '../data_to_score/artDCGAN_portrait128')\n",
    "Calculating FID with 1024 images from each distribution\n",
    "FID calculation time: 114.940349 s\n",
    "FID: 133.7595\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_nudeportrait128', '../data_to_score/artDCGAN_nudeportrait128')\n",
    "Calculating FID with 1024 images from each distribution\n",
    "FID calculation time: 126.322527 s\n",
    "FID: 167.63837\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_landscape128', '../data_to_score/noise128')\n",
    "Calculating FID with 3162 images from each distribution\n",
    "FID calculation time: 230.036537 s\n",
    "FID: 423.57306\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_portrait128', '../data_to_score/noise128')\n",
    "Calculating FID with 3064 images from each distribution\n",
    "FID calculation time: 235.178896 s\n",
    "FID: 459.28424\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_nudeportrait128', '../data_to_score/noise128')\n",
    "Calculating FID with 3033 images from each distribution\n",
    "FID calculation time: 233.117534 s\n",
    "FID: 491.06567\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_landscape64', '../data_to_score/landscapeGANGogh')\n",
    "Calculating FID with 768 images from each distribution\n",
    "FID calculation time: 107.710434 s\n",
    "FID: 184.97502\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_landscape64', '../data_to_score/noise64')\n",
    "Calculating FID with 11218 images from each distribution\n",
    "FID calculation time: 424.221316 s\n",
    "FID: 437.08566\n",
    " -- \n",
    " \n",
    " \n",
    "('../data_to_score/source_landscape128', '../data_to_score/landscapeGANGogh_scaled128')\n",
    "Calculating FID with 768 images from each distribution\n",
    "FID calculation time: 131.614078 s\n",
    "FID: 232.7404\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_landscape64', '../data_to_score/artDCGAN_landscape128_scaled64')\n",
    "Calculating FID with 1024 images from each distribution\n",
    "FID calculation time: 119.485353 s\n",
    "FID: 61.031754\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_landscape128_scaled32', '../data_to_score/artDCGAN_landscape128_scaled32')\n",
    "Calculating FID with 1024 images from each distribution\n",
    "FID calculation time: 117.110968 s\n",
    "FID: 79.60612\n",
    " -- \n",
    "\n",
    "('../data_to_score/source_landscape128_scaled64', '../data_to_score/artDCGAN_landscape128_scaled64')\n",
    "Calculating FID with 1024 images from each distribution\n",
    "FID calculation time: 117.648679 s\n",
    "FID: 75.05792\n",
    " -- \n",
    " \n",
    "('../data_to_score/source_landscape128_scaled64', '../data_to_score/landscapeGANGogh')\n",
    "Calculating FID with 768 images from each distribution\n",
    "FID calculation time: 120.625967 s\n",
    "FID: 186.45053\n",
    " -- \n",
    " \n",
    " ('../data_to_score/source_landscape128_scaled32', '../data_to_score/landscapeGANGogh_scaled32')\n",
    "Calculating FID with 768 images from each distribution\n",
    "FID calculation time: 120.758813 s\n",
    "FID: 109.41017\n",
    " -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_pairs = [\n",
    "    (\"../data_to_score/source_celebA_scaled64\", \"../data_to_score/DCGAN_celebA\"), \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('../data_to_score/source_celebA_scaled64', '../data_to_score/DCGAN_celebA')\n",
      "Calculating FID with 6656 images from each distribution\n",
      "FID calculation time: 329.229908 s\n",
      "FID: 100.46742\n",
      " -- \n",
      " \n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "logfile = open(\"logfile.txt\",\"a+\")\n",
    "\n",
    "for (source_folder, target_folder) in folder_pairs:\n",
    "    print((source_folder, target_folder))\n",
    "    logfile.write(str((source_folder, target_folder)) + \"\\n\")\n",
    "    source_images, source_images_transposed = load_images_from_folder(source_folder)\n",
    "    target_images, target_images_transposed = load_images_from_folder(target_folder)\n",
    "    \n",
    "    max_length = min(len(source_images_transposed), len(target_images_transposed))\n",
    "    \n",
    "    current_score = get_fid(source_images_transposed[:max_length], target_images_transposed[:max_length])\n",
    "    logfile.write(\"FID: \" + str(current_score) + \"\\n\")\n",
    "\n",
    "    print(\"FID: \" + str(current_score))\n",
    "    scores.append(current_score)\n",
    "    \n",
    "    logfile.write(\" -- \\n\\n\")\n",
    "\n",
    "    print(' -- ')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
